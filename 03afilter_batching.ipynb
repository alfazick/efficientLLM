{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter batch function subroutines\n",
    "import torch\n",
    "\n",
    "batch = {\n",
    "    \"input_ids\": torch.tensor([\n",
    "        [101, 102, 103],\n",
    "        [201, 202, 203],\n",
    "        [301, 302, 0]\n",
    "    ]),\n",
    "    \"position_ids\": torch.tensor([\n",
    "        [1, 2, 3],\n",
    "        [1, 2, 3],\n",
    "        [1, 2, 0]\n",
    "    ]),\n",
    "    \"attention_mask\": torch.tensor([\n",
    "        [1, 1, 1],\n",
    "        [1, 1, 1],\n",
    "        [1, 1, 0]\n",
    "    ]),\n",
    "    \"responses\": [\"Hello\", \"World\", \"Test\"],\n",
    "    \"tokens_remaining\": [3, 0, 2],\n",
    "    \"past_key_values\": (\n",
    "        ([torch.tensor([[1, 1, 1], [1, 1, 1], [1, 1, 0]]), torch.tensor([[2, 2, 2], [2, 2, 2], [2, 2, 0]])]),  # keys and values for each layer/head\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 0, 2]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# 1. Identify Entries to Remove\n",
    "def identify_removal_indeces(tokens_remaining):\n",
    "    \"\"\"Function finds all indexes, \n",
    "    which doesn't have tokens left\n",
    "    to response\n",
    "    \"\"\"\n",
    "    return [i for i,tokens in enumerate(tokens_remaining) if tokens <= 0]\n",
    "\n",
    "print(batch[\"tokens_remaining\"])\n",
    "remove_indices = identify_removal_indeces(batch[\"tokens_remaining\"])\n",
    "print(remove_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[101, 102, 103],\n",
      "        [201, 202, 203],\n",
      "        [301, 302,   0]])\n",
      "tensor([ True, False,  True])\n",
      "tensor([[101, 102, 103],\n",
      "        [301, 302,   0]])\n"
     ]
    }
   ],
   "source": [
    "#2. Create a Mask and Filter Tensors \n",
    "def create_mask_and_filter(batch, remove_indices):\n",
    "    mask = torch.ones(batch[\"input_ids\"].size(0),dtype = torch.bool)\n",
    "    mask[remove_indices] = False\n",
    "\n",
    "    # Apply the mask to tensors\n",
    "    filtered_batch = {\n",
    "        \"input_ids\":batch[\"input_ids\"][mask],\n",
    "        \"position_ids\":batch[\"position_ids\"][mask],\n",
    "        \"attention_mask\":batch[\"attention_mask\"][mask]\n",
    "    }\n",
    "\n",
    "    return filtered_batch, mask \n",
    "\n",
    "print(batch[\"input_ids\"])\n",
    "\n",
    "filtered_batch,mask = create_mask_and_filter(batch, remove_indices)\n",
    "print(mask)\n",
    "print(filtered_batch[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'Test']\n",
      "[3, 2]\n"
     ]
    }
   ],
   "source": [
    "# 3. Filter Lists\n",
    "def filter_lists(responses, tokens_remaining, remove_indices):\n",
    "    filtered_responses = [r for i, r in enumerate(responses) if i not in remove_indices]\n",
    "    filtered_tokens_remaining = [t for i, t in enumerate(tokens_remaining) if i not in remove_indices]\n",
    "    return filtered_responses, filtered_tokens_remaining\n",
    "\n",
    "filtered_responses, filtered_tokens_remaining = filter_lists(batch[\"responses\"], batch[\"tokens_remaining\"], remove_indices)\n",
    "\n",
    "print(filtered_responses)\n",
    "print(filtered_tokens_remaining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([tensor([[1, 1, 1],\n",
      "        [1, 1, 1],\n",
      "        [1, 1, 0]]), tensor([[2, 2, 2],\n",
      "        [2, 2, 2],\n",
      "        [2, 2, 0]])],)\n",
      "[(tensor([[1, 1, 1],\n",
      "        [1, 1, 0]]), tensor([[2, 2, 2],\n",
      "        [2, 2, 0]]))]\n"
     ]
    }
   ],
   "source": [
    "# 4. Filter Past Key Values\n",
    "def filter_past_key_values(past_key_values, mask):\n",
    "    new_past_key_values = []\n",
    "    # Iterate over each tuple in the past_key_values\n",
    "    for k, v in past_key_values:\n",
    "        # Apply the mask to both the key and value tensors\n",
    "        filtered_k = k[mask]\n",
    "        filtered_v = v[mask]\n",
    "        # Append the filtered key-value pairs back into the new list\n",
    "        new_past_key_values.append((filtered_k, filtered_v))\n",
    "    return new_past_key_values\n",
    "\n",
    "\n",
    "print(batch[\"past_key_values\"])\n",
    "filtered_past_key_values = filter_past_key_values(batch[\"past_key_values\"], mask)\n",
    "print(filtered_past_key_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Attention Mask:\n",
      " tensor([[0, 0, 1, 1, 1, 1, 1],\n",
      "        [0, 1, 1, 1, 1, 0, 0],\n",
      "        [0, 0, 0, 1, 1, 1, 1]])\n",
      "Truncated Attention Mask:\n",
      " tensor([[0, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 0, 0],\n",
      "        [0, 0, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "# 5. Truncate Left\n",
    "import torch\n",
    "\n",
    "# Define the attention_mask tensor with leading zeros\n",
    "attention_mask = torch.tensor([\n",
    "    [0, 0, 1, 1, 1, 1, 1],\n",
    "    [0, 1, 1, 1, 1, 0, 0],\n",
    "    [0, 0, 0, 1, 1, 1, 1]\n",
    "])\n",
    "\n",
    "def truncate_left(attention_mask):\n",
    "    # Identify positions of leading zeros and their cumulative product\n",
    "    zero_mask = attention_mask == 0\n",
    "    cumprod = zero_mask.cumprod(dim=1)\n",
    "    \n",
    "    # Calculate how many leading zeros are present in each sequence\n",
    "    leading_zeros_count = cumprod.sum(dim=1)\n",
    "    min_leading_zeros = torch.min(leading_zeros_count)\n",
    "    \n",
    "    # Determine the offset to truncate the matrix\n",
    "    truncation_offset = min_leading_zeros.item()\n",
    "    \n",
    "    # Truncate the attention_mask by removing columns from the start\n",
    "    truncated_attention_mask = attention_mask[:, truncation_offset:]\n",
    "    return truncated_attention_mask\n",
    "\n",
    "# Apply the truncate_left method to the attention_mask\n",
    "truncated_attention_mask = truncate_left(attention_mask)\n",
    "\n",
    "# Print the original and truncated attention masks\n",
    "print(\"Original Attention Mask:\\n\", attention_mask)\n",
    "print(\"Truncated Attention Mask:\\n\", truncated_attention_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
